{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5347b9",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center\"> Área académica de Ingeniería en Computadores </div> \n",
    "\n",
    "## <div style=\"text-align: center\"> CE - 5506 Introducción al Reconocimiento de Patrones </div>\n",
    "\n",
    "## <div style=\"text-align: center\"> Tarea #3 </div>\n",
    "\n",
    "## <div style=\"text-align: left\"> Estudiantes: </div> <br> <div style=\"text-align:center\"> Agüero Sandí Johnny - 2020027766 </div>\n",
    "    \n",
    "## <div style=\"text-align: left\"> Profesor: </div> <br> <div style=\"text-align: center\"> Jason Leiton Jimenez <br><br> </div>\n",
    "\n",
    "## <div style=\"text-align: center\"> Grupo 1 </div>\n",
    "\n",
    "## <div style=\"text-align: center\"> IS $-$ 2023 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f2164",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3864c9",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center\"> I Parte <br> --- <br> Analizando el código del archivo \"MLPNet Taller.ipynb\" </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec02809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111f34c",
   "metadata": {},
   "source": [
    "###  1) Modifique el código para entrenar una red con el set de datos MNIST con imágenes de 28x28. Debe modificar el tamaño de las capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc4152fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMulticapa_Modificado:\n",
    "    def __init__(self, capas, func_activacion_in=[\"sigmoide\"], alpha=0.1):\n",
    "        self.capas = capas\n",
    "        self.alpha = alpha\n",
    "        self.func_activacion = func_activacion_in\n",
    "        self.bias = []\n",
    "        self.pesos = []\n",
    "        # Inicializar los pesos y bias de cada capa\n",
    "        for i in range(0, len(capas) - 1):\n",
    "            peso = np.random.randn(capas[i], capas[i+1])\n",
    "            self.pesos.append(peso)\n",
    "            bias = np.random.randn(capas[i+1])\n",
    "            self.bias.append(bias)\n",
    "\n",
    "    def activacion(self, x, i):\n",
    "        if self.func_activacion[i] == \"sigmoide\":\n",
    "            return 1.0 / (1 + np.exp(-x))\n",
    "        elif self.func_activacion[i] == \"tanh\":\n",
    "            return np.tanh(x)\n",
    "        elif self.func_activacion[i] == \"ReLU\":\n",
    "            return np.maximum(0.01 * x, x)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def activacion_derivada(self, x , i):\n",
    "        if self.func_activacion[i] == \"sigmoide\":\n",
    "            return x * (1 - x)\n",
    "        elif self.func_activacion[i] == \"tanh\":\n",
    "            return 1 - x**2\n",
    "        elif self.func_activacion[i] == \"ReLU\":\n",
    "            return np.where(x > 0, 1, 0.01)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        capa_activacion = [X]\n",
    "        for i in range(0, len(self.capas) - 1):\n",
    "            x = np.dot(capa_activacion[i], self.pesos[i]) + self.bias[i]\n",
    "            y = self.activacion(x, i)\n",
    "            capa_activacion.append(y)\n",
    "        return capa_activacion\n",
    "\n",
    "    def backpropagation(self, X, y, capa_activacion):\n",
    "        error = capa_activacion[-1] - y\n",
    "        delta = error * self.activacion_derivada(capa_activacion[-1], -1)\n",
    "\n",
    "        for i in reversed(range(0, len(self.capas) - 1)):\n",
    "            activacion_actual = capa_activacion[i + 1]\n",
    "            activacion_anterior = capa_activacion[i]\n",
    "            d_peso = np.outer(activacion_anterior, delta)\n",
    "            d_bias = delta\n",
    "            self.pesos[i] -= self.alpha * d_peso\n",
    "            self.bias[i] -= self.alpha * d_bias\n",
    "            delta = np.dot(delta, self.pesos[i].T) * self.activacion_derivada(activacion_anterior, i)\n",
    "\n",
    "\n",
    "    def entrenar(self, X, y, epochs):\n",
    "        for epoch in range(0, epochs):\n",
    "            for i in range(0, len(X)):\n",
    "                capa_activacion = self.feedforward(X[i])\n",
    "                self.backpropagation(X[i], y[i], capa_activacion)\n",
    "\n",
    "    def predecir(self, X):\n",
    "        capa_activacion = self.feedforward(X)\n",
    "        return capa_activacion[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0f759",
   "metadata": {},
   "source": [
    "###  2) Importar el set da datos MNIST con imágenes de 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04186a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2a0de",
   "metadata": {},
   "source": [
    "###  3) Realice el proceso de feature engeneering antes de entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ffa82f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "[6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "cantidad_train = [0,0,0,0,0,0,0,0,0,0]\n",
    "for k in y_train:\n",
    "    cantidad_train[k] = cantidad_train[k] + 1\n",
    "\n",
    "cantidad_test = [0,0,0,0,0,0,0,0,0,0]\n",
    "for i in y_test:\n",
    "    cantidad_test[i] = cantidad_test[i] + 1\n",
    "    \n",
    "print(cantidad_train)\n",
    "print(cantidad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27b1be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de los datos\n",
    "# Redimensionar las imágenes de MNIST a un tamaño de 28x28 píxeles\n",
    "X_train = X_train.reshape((X_train.shape[0], 784))\n",
    "X_test = X_test.reshape((X_test.shape[0], 784))\n",
    "\n",
    "# Normalizar los valores de píxeles entre 0 y 1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Convertir las etiquetas a tipo entero\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Convertir las etiquetas a one-hot encoding\n",
    "num_classes = 10\n",
    "y_train = np.eye(num_classes, dtype=int)[y_train]\n",
    "y_test = np.eye(num_classes, dtype=int)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b2d45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar la red neuronal\n",
    "capas = [784, 128, 64, 10]  # Capas: 784 (entrada) - 128 - 64 - 10 (salida)\n",
    "start_time = time.time()\n",
    "mlp = PerceptronMulticapa_Modificado(capas, func_activacion_in=[\"sigmoide\",\"sigmoide\",\"sigmoide\",\"sigmoide\"], alpha=0.1)\n",
    "mlp.entrenar(X_train, y_train, epochs=10)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28465ea5",
   "metadata": {},
   "source": [
    "###  4) Obtenga las métricas de recall, precision, accuracy, F1 y tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a723068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar la red neuronal en el conjunto de prueba\n",
    "predicciones = np.argmax(mlp.predecir(X_test), axis=1)\n",
    "etiquetas_verdaderas = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be8cf9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones:  [9 2 1 ... 8 1 5]\n",
      "Y_Real      :  [9 2 1 ... 8 1 5]\n",
      "Accuracy: 0.8449\n",
      "Precisión: 0.8479107142995806\n",
      "Recall: 0.8449\n",
      "F1 Score: 0.8446869718947142\n",
      "Time: 282.37609791755676\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(etiquetas_verdaderas, predicciones)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(etiquetas_verdaderas, predicciones, average='weighted', zero_division=1)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(etiquetas_verdaderas, predicciones, average='weighted', zero_division=1)\n",
    "\n",
    "# Calcular la métrica F1\n",
    "f1 = f1_score(etiquetas_verdaderas, predicciones, average='weighted')\n",
    "\n",
    "# Time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Calcular de las predicciones\n",
    "print(\"Predicciones: \", predicciones)\n",
    "print(\"Y_Real      : \", etiquetas_verdaderas)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precisión: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc92870",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center\"> II Parte <br> --- <br> Parametrizar una red neuronal que clasifique los números utilizando el set de datos de MNIST. </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233bfcad",
   "metadata": {},
   "source": [
    "###  1) Realice una función que reciba como parámetros los siguientes elementos: una lista con la cantidad de neuronas en cada capa oculta, una lista con las funciones de activación en cada capa, un valor de α y la cantidad de epochs con la que se desea entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5725069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron_Parametrico(lista_capas, lista_funcionesActivacion, num_alpha, num_epochs):\n",
    "    start_time = time.time()\n",
    "    mlp = PerceptronMulticapa_Modificado(lista_capas, lista_funcionesActivacion, alpha=num_alpha)\n",
    "    mlp.entrenar(X_train, y_train, epochs=num_epochs)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Evaluar la red neuronal en el conjunto de prueba\n",
    "    predicciones = np.argmax(mlp.predecir(X_test), axis=1)\n",
    "    etiquetas_verdaderas = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(etiquetas_verdaderas, predicciones)\n",
    "\n",
    "    # Precision\n",
    "    precision = precision_score(etiquetas_verdaderas, predicciones, average='weighted', zero_division=1)\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(etiquetas_verdaderas, predicciones, average='weighted', zero_division=1)\n",
    "\n",
    "    # Calcular la métrica F1\n",
    "    f1 = f1_score(etiquetas_verdaderas, predicciones, average='weighted')\n",
    "\n",
    "    # Time\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    return accuracy, precision, recall, f1, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d6558",
   "metadata": {},
   "source": [
    "###  2) Modifique el código proporcionado para crear una red con las capas y funciones deseadas. Aquí se debe tener cuidado con las dimensiones de los pesos y del bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756328d",
   "metadata": {},
   "source": [
    "##### El código proporcionado en la sección uno se encuentra modificado para la implementación correspondiente. Se puede analizar el código para poder comprender las modificaciones necesarias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24810c",
   "metadata": {},
   "source": [
    "###  3) Posteriormente entrene la red con el 80% de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f62845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_func, precision_func, recall_func, f1_func, elapsed_time_func = Perceptron_Parametrico([784, 128, 64, 10], [\"sigmoide\",\"sigmoide\",\"sigmoide\",\"sigmoide\"], 0.1, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bebd45",
   "metadata": {},
   "source": [
    "###  4) Obtenga las métricas de recall, precision, accuracy, F1 y tiempo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fa3d843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8531\n",
      "Precisión: 0.856800799137158\n",
      "Recall: 0.8531\n",
      "F1 Score: 0.8533677460497\n",
      "Time: 431.7297079563141\n"
     ]
    }
   ],
   "source": [
    "# Calcular de las predicciones\n",
    "print(f\"Accuracy: {accuracy_func}\")\n",
    "print(f\"Precisión: {precision_func}\")\n",
    "print(f\"Recall: {recall_func}\")\n",
    "print(f\"F1 Score: {f1_func}\")\n",
    "print(f\"Time: {elapsed_time_func}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
